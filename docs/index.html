<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Agricultural Land Abandonment in Nepal – Agricultural Land Abandonment</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-0774fc528949661fb60d8774007a227f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


</head>

<body class="floating quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#aal-definition" id="toc-aal-definition" class="nav-link active" data-scroll-target="#aal-definition">1. Establish a quantifiable definition of AAL</a>
  <ul class="collapse">
  <li><a href="#rationale-for-this-definition" id="toc-rationale-for-this-definition" class="nav-link" data-scroll-target="#rationale-for-this-definition">1.1. Rationale for this definition</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">2. Develop a method to identify AAL satisfying the definition</a>
  <ul class="collapse">
  <li><a href="#review-of-existing-methods" id="toc-review-of-existing-methods" class="nav-link" data-scroll-target="#review-of-existing-methods">2.1. Review of existing methods</a>
  <ul class="collapse">
  <li><a href="#comparison-of-methods" id="toc-comparison-of-methods" class="nav-link" data-scroll-target="#comparison-of-methods">2.1.1 Comparison of Methods</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#suggested-methodology" id="toc-suggested-methodology" class="nav-link" data-scroll-target="#suggested-methodology">3. Suggested Methodology</a>
  <ul class="collapse">
  <li><a href="#multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm" id="toc-multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm" class="nav-link" data-scroll-target="#multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm">Multitemporal Object-oriented Image Analysis Based on Phenology using landTrendr algorithm</a></li>
  <li><a href="#rationale-for-the-using-the-methodology" id="toc-rationale-for-the-using-the-methodology" class="nav-link" data-scroll-target="#rationale-for-the-using-the-methodology">3.1. Rationale for the using the Methodology</a></li>
  <li><a href="#suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018" id="toc-suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018" class="nav-link" data-scroll-target="#suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018">3.2. Suggested Methodology in Detail (based on <span class="citation" data-cites="yinMappingAgriculturalLand2018 wuMonitoringCroplandAbandonment2023 daraMappingTimingCropland2018">(Dara et al., 2018; Wu et al., 2023; Yin et al., 2018)</span>)</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Agricultural Land Abandonment in Nepal</h1>
</div>



<div class="quarto-title-meta column-page-right">

    
  
    
  </div>
  


</header>


<p><strong>Problem:</strong> Identify abandoned agricultural lands (AAL) in Nepal.</p>
<p><strong>Solution (Conceptual):</strong> Establish a quantifiable definition of AAL → Develop a method to identify AAL satisfying the definition.</p>
<section id="aal-definition" class="level1">
<h1>1. Establish a quantifiable definition of AAL</h1>
<p>There is no universal definition of AAL. However, “time-based” and “land cover transition” definitions can be found in the literatures.</p>
<ul>
<li>Time-based definition: AAL is a land that has been abandoned for a certain period of time.</li>
<li>Land cover transition definition: AAL is a land that has been converted from agricultural land to non-agricultural land.</li>
</ul>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Suggested definition for this study</strong></p>
<p>Agricultural land abandonment is defined as arable land (khet or bari) where farming activities have ceased for a minimum of five consecutive years, leading to a transition to grassland, shrubland, or scrub, but which has not been converted to built-up areas, water bodies, or mature forest <span class="citation" data-cites="paudelHighResolutionRemoteSensing2025 raiStatusFarmlandAbandonment2019">(<a href="#ref-paudelHighResolutionRemoteSensing2025" role="doc-biblioref">Paudel et al., 2025</a>; <a href="#ref-raiStatusFarmlandAbandonment2019" role="doc-biblioref">Rai et al., 2019</a>)</span>.</p>
</div>
</div>
</div>
<section id="rationale-for-this-definition" class="level2">
<h2 class="anchored" data-anchor-id="rationale-for-this-definition">1.1. Rationale for this definition</h2>
<ul>
<li>Quantifiable supported by FAO (FAO, 2016)</li>
<li>Avoids misclassifying temporary fallow land</li>
</ul>
</section>
</section>
<section id="methods" class="level1">
<h1>2. Develop a method to identify AAL satisfying the definition</h1>
<p>Literatures before 2019 were reviewed from papers cited in <span class="citation" data-cites="gogaReviewApplicationRemote2019">(<a href="#ref-gogaReviewApplicationRemote2019" role="doc-biblioref">Goga et al., 2019</a>)</span>. Papers published after 2019 were reviewed from google scholar with custom date filter and <span class="citation" data-cites="liuGlobalReviewMonitoring2025a">(<a href="#ref-liuGlobalReviewMonitoring2025a" role="doc-biblioref">Liu et al., 2025</a>)</span>. Review was non-exhaustive till 2026-01-16 16:35.</p>
<section id="review-of-existing-methods" class="level2">
<h2 class="anchored" data-anchor-id="review-of-existing-methods">2.1. Review of existing methods</h2>
<p>Based on <span class="citation" data-cites="liuGlobalReviewMonitoring2025a">(<a href="#ref-liuGlobalReviewMonitoring2025a" role="doc-biblioref">Liu et al., 2025</a>)</span>, the methods can be divided into two major categories (Image classification &amp; spectral features method and Time-dynamic &amp;trajectory method) and various sub categories.</p>
<ul>
<li>Image Classification and Spectral Features Methods: This includes visual interpretation, supervised classification (SVM, Random Forest), decision trees, object-oriented classification (OBIA), and integrated methods (fusion of techniques).</li>
<li>Time-Dynamic and Trajectory Methods: This includes dual time-point change detection, multi-time point land cover trajectories (like LandTrendr), and vegetation phenology dynamics.</li>
</ul>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    classDef default font-size:20px;

    %% Main Node
    Start[Methods for AAL Detection]

    %% Main Categories
    CA[Image classification and &lt;br&gt; spectral features method]
    TT[Time-dynamic and &lt;br&gt; trajectory method]

    %% CA Sub-points
    CA_1[Visual &lt;br&gt; interpretation]
    CA_2[Supervised &lt;br&gt; classification]
    CA_3[Decision &lt;br&gt; trees]
    CA_4[Object-oriented &lt;br&gt; classification]
    CA_5[Integrated &lt;br&gt; methods]
    
    %% TT Sub-points
    TT_1[Dual time point &lt;br&gt; land cover changes &lt;br&gt; Multi-time point &lt;br&gt; land cover trajectory]
    TT_2[Vegetation phenology and &lt;br&gt; dynamic]

    %% Connections
    Start --&gt; TT
    Start --&gt; CA

    TT --&gt; TT_1
    TT --&gt; TT_2

    CA --&gt; CA_1
    CA --&gt; CA_2
    CA --&gt; CA_3
    CA --&gt; CA_4
    CA --&gt; CA_5

    %% Styling
    style Start fill:#2c3e50,stroke:#34495e,stroke-width:4px,color:#fff,font-weight:bold
    style TT fill:#3498db,stroke:#2980b9,stroke-width:2px,color:#fff
    style CA fill:#27ae60,stroke:#229954,stroke-width:2px,color:#fff
    
    style TT_1 fill:#ebf5fb,stroke:#3498db,stroke-dasharray: 5 5
    style TT_2 fill:#ebf5fb,stroke:#3498db,stroke-dasharray: 5 5
    
    style CA_1 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5
    style CA_2 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5
    style CA_3 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5
    style CA_4 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5
    style CA_5 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/review_summary.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="@liuGlobalReviewMonitoring2025a"><img src="images/review_summary.png" class="img-fluid figure-img" alt="Liu et al. (2025)"></a></p>
<figcaption><span class="citation" data-cites="liuGlobalReviewMonitoring2025a">Liu et al. (<a href="#ref-liuGlobalReviewMonitoring2025a" role="doc-biblioref">2025</a>)</span></figcaption>
</figure>
</div>
<section id="comparison-of-methods" class="level3">
<h3 class="anchored" data-anchor-id="comparison-of-methods">2.1.1 Comparison of Methods</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/review_method_comparison.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="@liuGlobalReviewMonitoring2025a"><img src="images/review_method_comparison.png" class="img-fluid figure-img" alt="Liu et al. (2025)"></a></p>
<figcaption><span class="citation" data-cites="liuGlobalReviewMonitoring2025a">Liu et al. (<a href="#ref-liuGlobalReviewMonitoring2025a" role="doc-biblioref">2025</a>)</span></figcaption>
</figure>
</div>
<div id="tbl-methods-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-methods-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Comprehensive Comparison of Remote Sensing Methods for Abandoned Agricultural Land (AAL) Detection
</figcaption>
<div aria-describedby="tbl-methods-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Study</th>
<th style="text-align: left;">Approach</th>
<th style="text-align: left;">Study Area</th>
<th style="text-align: left;">Data Sources (Spatial &amp; Temporal)</th>
<th style="text-align: left;">Definition of Abandonment</th>
<th style="text-align: left;">Methodology / Algorithm</th>
<th style="text-align: left;">Accuracy / Performance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong><span class="citation" data-cites="alcantaraMappingExtentAbandoned2013">(<a href="#ref-alcantaraMappingExtentAbandoned2013" role="doc-biblioref">Alcantara et al., 2013</a>)</span></strong></td>
<td style="text-align: left;">Multi-temporal (MA)</td>
<td style="text-align: left;">Central &amp; Eastern Europe</td>
<td style="text-align: left;"><strong>MODIS NDVI</strong> (250m)<br>Time-series: 2003–2009</td>
<td style="text-align: left;"><strong>Class-based (Static):</strong> Land cultivated in the socialist period but covered by successional vegetation (grass/shrubs) during observation.</td>
<td style="text-align: left;"><strong>SVM:</strong> Phenological metrics (start of season, amplitude) extracted via TIMESAT.</td>
<td style="text-align: left;"><strong>Moderate:</strong> ~49% area-adjusted overall accuracy.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><span class="citation" data-cites="estelMappingFarmlandAbandonment2015">(<a href="#ref-estelMappingFarmlandAbandonment2015" role="doc-biblioref">Estel et al., 2015</a>)</span></strong></td>
<td style="text-align: left;">Multi-temporal (MA)</td>
<td style="text-align: left;">Europe</td>
<td style="text-align: left;"><strong>MODIS NDVI</strong> (250m)<br>Time-series: 2001–2012</td>
<td style="text-align: left;"><strong>Trajectory-based:</strong> Land unmanaged/fallow for 2–5 consecutive years.</td>
<td style="text-align: left;"><strong>Random Forest (RF):</strong> Annual classification of “Active” vs.&nbsp;“Fallow” using normalized NDVI curves.</td>
<td style="text-align: left;"><strong>High:</strong> ~90.1% average overall accuracy for active/fallow distinction.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><span class="citation" data-cites="stefanskiMappingMonitoringLand2014">(<a href="#ref-stefanskiMappingMonitoringLand2014" role="doc-biblioref">Stefanski et al., 2014</a>)</span></strong></td>
<td style="text-align: left;">OBIA / Multi-sensor</td>
<td style="text-align: left;">Western Ukraine</td>
<td style="text-align: left;"><strong>Landsat</strong> (Optical) + <strong>ERS SAR</strong> (Radar)<br>Years: 1986, 1993, 1999, 2006, 2010</td>
<td style="text-align: left;"><strong>Trajectory-based:</strong> Land cover transition (Cropland → Grassland) without recultivation.</td>
<td style="text-align: left;"><strong>OBIA + RF:</strong> Superpixel Contour segmentation to delineate fields. Fusion of Optical and Radar.</td>
<td style="text-align: left;"><strong>83.4%</strong> Overall Accuracy. 87.2% for 2010 management regimes.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><span class="citation" data-cites="lowMappingAbandonedAgricultural2015">(<a href="#ref-lowMappingAbandonedAgricultural2015" role="doc-biblioref">Löw et al., 2015</a>)</span></strong></td>
<td style="text-align: left;">OBIA / Fusion</td>
<td style="text-align: left;">Kazakhstan</td>
<td style="text-align: left;"><strong>Landsat</strong> + <strong>RapidEye</strong><br>Time-series: 2009–2014</td>
<td style="text-align: left;"><strong>Trajectory-based:</strong> Analyzed within historical field parcels. Abandonment = 5 years of shrub/bare cover.</td>
<td style="text-align: left;"><strong>Decision Fusion:</strong> Trained RF and SVM separately on object-based features and fused results via majority voting.</td>
<td style="text-align: left;"><strong>~97%</strong> Overall Accuracy. Fusing classifiers significantly improved accuracy over single algorithms.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><span class="citation" data-cites="yinMappingAgriculturalLand2018">(<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span></strong></td>
<td style="text-align: left;">OBIA / LandTrendr</td>
<td style="text-align: left;">Caucasus (Russia/Georgia)</td>
<td style="text-align: left;"><strong>Landsat time series</strong> (30m)<br>1985–2015</td>
<td style="text-align: left;"><strong>Dynamic/Trajectory:</strong> Land inactive for at least 5 years (based on FAO definition).</td>
<td style="text-align: left;"><strong>RF + LandTrendr:</strong> Multi-resolution segmentation into objects. RF for annual probability, then LandTrendr for temporal segmentation.</td>
<td style="text-align: left;"><strong>97% ± 1%</strong> Overall Accuracy. Performed substantially better than pixel-level detection (82%).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><span class="citation" data-cites="wuMonitoringCroplandAbandonment2023">(<a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>)</span></strong></td>
<td style="text-align: left;">OBIA / LandTrendr</td>
<td style="text-align: left;">Fujian Province, China</td>
<td style="text-align: left;"><strong>Landsat</strong> + <strong>Sentinel-2</strong> (10-30m)<br>2010–2021</td>
<td style="text-align: left;"><strong>Narrow Sense:</strong> Farmland not cultivated for 1 year or more.</td>
<td style="text-align: left;"><strong>RF + LandTrendr:</strong> Used existing government farmland plot boundaries. RF for annual probability, then LandTrendr to identify significant drops.</td>
<td style="text-align: left;"><strong>High:</strong> 87.02% (2018) and 87.50% (2020) validation accuracy.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><span class="citation" data-cites="daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>)</span></strong></td>
<td style="text-align: left;">Multi-temporal (MA)</td>
<td style="text-align: left;">Northern Kazakhstan</td>
<td style="text-align: left;"><strong>Landsat time series</strong> (30m)<br>1984–2016</td>
<td style="text-align: left;"><strong>Trajectory-based:</strong> 3 consecutive years active followed by 3 consecutive years inactive.</td>
<td style="text-align: left;"><strong>RF + LandTrendr:</strong> 3-year moving window for spectral metrics. RF for annual cropland probability, then LandTrendr for trajectory analysis.</td>
<td style="text-align: left;"><strong>89%</strong> Overall Accuracy. UA of 93% for the abandonment class.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><span class="citation" data-cites="gunthertObjectbasedDetectionLUCC2011">(<a href="#ref-gunthertObjectbasedDetectionLUCC2011" role="doc-biblioref">Günthert et al., 2011</a>)</span></strong></td>
<td style="text-align: left;">Texture / Edge Detection</td>
<td style="text-align: left;">Tenerife (Canary Islands)</td>
<td style="text-align: left;"><strong>RapidEye</strong> + <strong>Orthophotos</strong><br>2010</td>
<td style="text-align: left;"><strong>Subtraction Method:</strong> (Total Ever-Utilized Area) minus (Current Active Agriculture).</td>
<td style="text-align: left;"><strong>Canny Filter within OBIA:</strong> Detects “linear footprints” (terraces/walls) under vegetation to identify long-term fallow.</td>
<td style="text-align: left;"><strong>93.0%</strong> Overall Accuracy. Highly effective for abandoned terraces.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><span class="citation" data-cites="shixinObjectorientedClassificationTechnique2013">(<a href="#ref-shixinObjectorientedClassificationTechnique2013" role="doc-biblioref">Shixin et al., 2013</a>)</span></strong></td>
<td style="text-align: left;">OBIA (Rule-based)</td>
<td style="text-align: left;">China</td>
<td style="text-align: left;"><strong>SPOT-5</strong> (2.5m/10m)<br>Nov 2010</td>
<td style="text-align: left;"><strong>Land Cover Class:</strong> Identification of abandoned land as a specific spectral/structural class.</td>
<td style="text-align: left;"><strong>OBIA:</strong> Edge-based segmentation + rules involving spectral signatures, shape, and texture.</td>
<td style="text-align: left;"><strong>78.94%</strong> accuracy for Abandoned Class. Outperformed pixel-based methods (~59%).</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong><span class="citation" data-cites="goodinMappingLandCover2015">(<a href="#ref-goodinMappingLandCover2015" role="doc-biblioref">Goodin et al., 2015</a>)</span></strong></td>
<td style="text-align: left;">OBIA / SVM</td>
<td style="text-align: left;">Poland / Ukraine Border</td>
<td style="text-align: left;"><strong>Landsat 8 OLI</strong> (Single date)<br>Aug 2013</td>
<td style="text-align: left;"><strong>Land Use Distinction:</strong> Differentiating “Pasture/Abandoned” from active “Arable” land.</td>
<td style="text-align: left;"><strong>SVM within OBIA:</strong> Combined spectral features with object geometry (shape/size).</td>
<td style="text-align: left;"><strong>75%</strong> Overall Accuracy for land use. Spatial features were essential for land use separation.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong><span class="citation" data-cites="suziedelytevisockieneAnalysisIdentificationAbandoned2019">(<a href="#ref-suziedelytevisockieneAnalysisIdentificationAbandoned2019" role="doc-biblioref">Suziedelyte Visockiene et al., 2019</a>)</span></strong></td>
<td style="text-align: left;">Segmentation</td>
<td style="text-align: left;">Lithuania</td>
<td style="text-align: left;"><strong>Sentinel-2</strong> (Optical)<br>Sept 2017</td>
<td style="text-align: left;"><strong>Verification:</strong> Land covered with woody plants identified by remote sensing and compared with national registry.</td>
<td style="text-align: left;"><strong>Mean-Shift Segmentation:</strong> Clustering and Kernel density (ColorMapping) to find homogenous scrub regions.</td>
<td style="text-align: left;"><strong>Varied:</strong> ~94% (Winter), ~75% (Summer). Accuracy depends on seasonal vegetation state.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Expand for details
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="time-dynamic-and-trajectory-methods" class="level3">
<h3 class="anchored" data-anchor-id="time-dynamic-and-trajectory-methods">2.1.1. Time-Dynamic and Trajectory Methods</h3>
<p>These papers utilize advanced non-parametric classifiers like Random Forest (RF) and Support Vector Machine (SVM) and LandTrendR applied to time series data (mostly landsat and MODIS) to identify AAL.</p>
<ul>
<li><span class="citation" data-cites="alcantaraMappingExtentAbandoned2013">(<a href="#ref-alcantaraMappingExtentAbandoned2013" role="doc-biblioref">Alcantara et al., 2013</a>)</span> used Support Vector Machine (SVM) on MODIS NDVI time series to map active and fallow agricultural lands across Europe.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Alacantara et al.&nbsp;(2013)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Objective: (1) What are the spatial patterns of currently abandoned farmland in Central and Eastern Europe?</li>
</ul>
<ol start="2" type="1">
<li>Are abandoned farmlands more strongly associated with institutional and socio-economic factors or with biophysical factors?</li>
</ol>
<ul>
<li>Definition: “Abandoned agriculture” was defined as land likely cultivated during the socialist period but covered by successional vegetation during the observation period. They classified pixels directly into four static classes: active agriculture, forest, abandoned agriculture, and other.</li>
<li>Datasets:MODIS (both Aqua and Terra) NDVI time series (2003-2009) was classified into- active agriculture (cropland and pastures), forest, abandoned agriculture, and others (water, urban, rocks and wetland) using Support Vector Machine (SVM). TIMESAT software to extract specific phenological metrics. These included the start/end of the growing season, base/maximum NDVI, and the length of the growing cycle. They used 108 total bands (metrics plus monthly NDVI) as input</li>
<li>Classification: They did not rely primarily on visual interpretation of the MODIS pixels themselves. Instead, they used an upscaling approach. They gathered training data from existing high-resolution (30m) Landsat land-cover maps produced in previous local studies. They selected MODIS pixels that contained at least 90% of a single class (e.g., abandoned agriculture) within the finer Landsat maps</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="estelMappingFarmlandAbandonment2015">(<a href="#ref-estelMappingFarmlandAbandonment2015" role="doc-biblioref">Estel et al., 2015</a>)</span>,used Random Forest classifier on MODIS NDVI time series (2001-2012) to map active and fallow agricultural lands across Europe.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Estel et al.&nbsp;(2015)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Defined fallow farmland as “land without management (i.e., not sown, cropped, or plowed in the case of cropland, or not mown or intensively grazed in the case of grassland)”.</li>
<li>Datasets: MODIS NDVI (16 day composite Aqua &amp; Terra), MODIS land surface temperature (to distinguish winter from growing season), MODIS land-water mask- MOD44W (to separate land area), GlobCORINE land cover (to define extent of potentially active or fallow agricultural land), training data-visual interpretation of MODIS NDVI profiles combined with high-res Google Earth images. They looked for specific phenological shapes: “bell-shaped” curves indicated fallow/natural vegetation, while irregular, narrow peaks indicated active management (plowing/harvest)</li>
<li>Classification: They classified each pixel for each year as either “Active” or “Fallow” using RF classifier. Then, for each pixel, they calculated fallow frequency. Abandoned was then defined based on the trajectory (2-5 years of fallow years)</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="mullerComparingDeterminantsCropland2013">(<a href="#ref-mullerComparingDeterminantsCropland2013" role="doc-biblioref">Müller et al., 2013</a>)</span> A pixel was classified as “abandoned” if it was covered by cropland in the first time step (e.g., 1990) but was not cropland (non-cropland) in the subsequent time step (e.g., 1995). Cannot use this because it does not consider temporary fallow agricultural land.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Estel et al.&nbsp;(2015) vs Alcantara et al.&nbsp;(2013)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="tbl-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Table 1: Major Differences Between the Two Methods
</figcaption>
<div aria-describedby="tbl-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Estel et al.&nbsp;(2015)</th>
<th style="text-align: left;">Alcantara et al.&nbsp;(2013)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Output Type</strong></td>
<td style="text-align: left;"><strong>Annual Maps</strong>: Produces a map for every year (2001–2012) to track trajectories.</td>
<td style="text-align: left;"><strong>Static Map</strong>: Produces a single map representing the state of abandonment around 2005.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Input Features</strong></td>
<td style="text-align: left;"><strong>Normalized Time Series</strong>: Used the shape of the NDVI curve directly after normalizing for climate differences.</td>
<td style="text-align: left;"><strong>Phenological Metrics</strong>: Extracted specific statistics (e.g., start of season, amplitude) using TIMESAT software.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Algorithm</strong></td>
<td style="text-align: left;"><strong>Random Forest (RF)</strong>: Uses an ensemble of decision trees.</td>
<td style="text-align: left;"><strong>Support Vector Machines (SVM)</strong>: Fits optimal hyperplanes to separate classes.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Training Data</strong></td>
<td style="text-align: left;"><strong>Visual Interpretation</strong>: Experts labeled points by looking at Google Earth and NDVI profiles.</td>
<td style="text-align: left;"><strong>Upscaling/Fusion</strong>: Used existing high-resolution Landsat maps to train the coarse MODIS classifier.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Abandonment Logic</strong></td>
<td style="text-align: left;"><strong>Frequency-based</strong>: A pixel is “abandoned” only if it is classified as “fallow” for several consecutive years.</td>
<td style="text-align: left;"><strong>Class-based</strong>: The classifier is trained to recognize the specific spectral signature of “abandonment” as a distinct land cover class.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Accuracy</strong></td>
<td style="text-align: left;">More Accurate</td>
<td style="text-align: left;">Less Accurate</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</div>
<p><span class="citation" data-cites="yinMappingAgriculturalLand2018 wuMonitoringCroplandAbandonment2023 daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span> share a core methodological framework for mapping AAL using LandTrendr algorithm on agricultural land probability (probabilities of pixel/object being cropland using Random Forest).</p>
<ul>
<li>Core Algorithm: All three studies utilize the LandTrendr (Landsat-based detection of Trends in Disturbance and Recovery) algorithm to analyze temporal trajectories. They all first employ a Random Forest classifier to generate annual probability maps (estimating the likelihood of a pixel/object being cropland) and then feed these probability time series into LandTrendr to detect structural breaks.</li>
<li>Classification Probabilities: All of them use Random Forest to perform the initial classification of cropland probabilities based on spectral metrics.</li>
<li>Trajectory Analysis: They distinguish stable cropland from abandoned and recultivated cropland based on the trajectory of the probability values over time.</li>
<li>Major difference: <span class="citation" data-cites="daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>)</span> addressed data scarcity by calculating spectral metrics using a 3-year moving window rather than single-year images. <span class="citation" data-cites="yinMappingAgriculturalLand2018">(<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span> included imagery from +- 1 year around the target year to calculate spectral-temporal metrics and reduce classification error due to data gaps. <span class="citation" data-cites="wuMonitoringCroplandAbandonment2023">(<a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>)</span> combined Landsat with Sentinel-2 data and used monthly synthetic cloud-free images set to construct their time series, rather than multi-year moving window.</li>
</ul>
</section>
<section id="image-classification-and-spectral-features-methods" class="level3">
<h3 class="anchored" data-anchor-id="image-classification-and-spectral-features-methods">2.1.2. Image Classification and Spectral Features Methods</h3>
<p>These papers deviate away from the pixel-based approach towards object-based image analysis (OBIA), multi-sensor data fusion, and long-term tragectory analysis.</p>
<ul>
<li><span class="citation" data-cites="stefanskiMappingMonitoringLand2014">(<a href="#ref-stefanskiMappingMonitoringLand2014" role="doc-biblioref">Stefanski et al., 2014</a>)</span> (Optical-Radar Fusion &amp; Trajectory Analysis): This study focuses on the post-Soviet Western Ukraine and utilizes a method that integrates different sensor types to overcome data gaps and spectral confusion.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Stefanski et al.&nbsp;(2014)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Data: They combined optical data (Landsat) with Radar data (ERS SAR) for the years 1986, 1993, 1999, 2006, and 2010.</li>
<li>Method: They applied OBIA approach using “Superpixel Contour” segmentation to delineate fields. They then classified these objects using Random Forest classifier.</li>
<li>Abandonment: Abandonment was identified through land cover trajectory analysis. They tracked the trajectory of each object across the five time steps. E.g., Cropland → Grassland (without recultivation) = Permanent Abandonment</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="lowMappingAbandonedAgricultural2015">(<a href="#ref-lowMappingAbandonedAgricultural2015" role="doc-biblioref">Löw et al., 2015</a>)</span> (Decision Fusion &amp; Historical Vector Masking): Focused on Kazakhstan, this paper introduces a “Decision Fusion” technique to improve accuracy in complex irrigated landscape.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Low et al.&nbsp;(2015)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Data: Time series of Landsat and RapidEye imagery (2009-2014)</li>
<li>Method: They used two different machine learning algorithms, RF and SVM to classify the data. they then fused the results of these two classifiers to achieve higher accuracy (up tp 97%) than either could achieve alone.</li>
<li>Abandonment: They digitized all formerly used field parcels (from Soviet era) using hi-res imagery to create a mask. They then analyzed the land cover trahectories within the specific polygons to identify abandonment. E.g., 5 consecutive years of shrub cover/bare.</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="gunthertObjectbasedDetectionLUCC2011">(<a href="#ref-gunthertObjectbasedDetectionLUCC2011" role="doc-biblioref">Günthert et al., 2011</a>)</span> (Texture-Based “Subtraction” Method): Günthert et al.&nbsp;developed a unique “subtraction” method that relies on identifying physical land structures rather than just vegetation health. Their approach was driven by the specific landscape of Tenerife, where agriculture relies on terraces that remain visible even long after the land has been abandoned and covered by natural vegetation</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Günthert et al.&nbsp;(2011)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Data: RapidEye satellite imagery &amp; hi-res orthophotos</li>
<li>Method: OBIA approach on rapidEye to id current active crops. Applied Canny edge detector on very hi-res orthophotos to find the “footprint” of all agriculture past and present. This is termed as “Total Ever-utilized” land. Instead of loooking for green vegetation, they looked for linear structures like terrace walls, plough dfurrows, and field boundaries. They used a Canny edge detector filter to highlight these lines, followed by a density analysis to identify areas with a high concentration of man-made lines. This allowed them to detect old agricultural land even if it was covered in dense shrubs or forest (advanced secondary succession).</li>
<li>Abandonment:They calculated abandonment by subtracting the Current Active Agriculture (Step 1) from the Total Ever-Utilized Area (Step 2). Any area that had agricultural terraces (Step 2) but was not currently being farmed (Step 1) was classified as abandoned/non-active</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="shixinObjectorientedClassificationTechnique2013">(<a href="#ref-shixinObjectorientedClassificationTechnique2013" role="doc-biblioref">Shixin et al., 2013</a>)</span> This paper focuses on proving the superiority of object-based methods over pixel-based methods using high-resolution data in China.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Shixin et al.&nbsp;(2013)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Data: SPOT-5 high-resolution imagery (2.5m panchromatic and 10m multispectral)</li>
<li>Method: They performed Edge-based segmentation in ENVI software to create image objects. They then classified these objects using a rule-based system involving spectral signatures, shape, texture, and spatial location.</li>
<li>Abandonment: They compared this directly with a standard pixel-based Maximum Likelihood classification. The object-oriented method achieved an accuracy of 78.94% for abandoned farmland, whereas the pixel-based method achieved only 59.00%, primarily because abandoned land is spectrally complex (mixed weeds, soil, water) and confuses pixel-based classifiers</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="goodinMappingLandCover2015">(<a href="#ref-goodinMappingLandCover2015" role="doc-biblioref">Goodin et al., 2015</a>)</span> This study explicitly tests which components of an object (spectral vs.&nbsp;spatial) are necessary to identify land use (abandonment) versus land cover.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Goodin et al.&nbsp;(2015)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Data: Single-date Landsat 8 OLI imagery (pan-sharpened)</li>
<li>Method: They used Support Vector Machines (SVM) within an Object-Based Image Analysis (OBIA) framework. They ran three variations: using only spectral features, using only spatial/geometric features, and using combined features</li>
<li>Abandonment: They found that for land use (which includes distinguishing “Pasture/Abandoned” from active “Arable”), using combined spectral and spatial features yielded the highest accuracy. This confirms that the shape and size of agricultural plots (geometry) are critical cues for identifying abandonment in fragmented landscapes</li>
</ul>
</div>
</div>
</div>
<ul>
<li><span class="citation" data-cites="suziedelytevisockieneAnalysisIdentificationAbandoned2019">(<a href="#ref-suziedelytevisockieneAnalysisIdentificationAbandoned2019" role="doc-biblioref">Suziedelyte Visockiene et al., 2019</a>)</span> (Segmentation &amp; Spatial Data Comparison) This paper analyzes abandoned land in Lithuania using open-source satellite data and compares it to national registry data.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Details Suziedelyte-Visockiene et al.&nbsp;(2019)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Data: Sentinel-2 optical data.</li>
<li>Method: They used the Mean-Shift segmentation algorithm to group pixels into regions of homogeneous color and density. They used a “ColorMapping” application based on Kernel density estimation.</li>
<li>Abandonment: They compared the results of this segmentation with the national “collection of spatial data on abandoned agricultural land” (vector data provided by the National Land Service). This served as a validation of using remote sensing to update official national statistics</li>
</ul>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="suggested-methodology" class="level1">
<h1>3. Suggested Methodology</h1>
<section id="multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm">Multitemporal Object-oriented Image Analysis Based on Phenology using landTrendr algorithm</h2>
<p>Based on the review of literature (<span class="citation" data-cites="gogaReviewApplicationRemote2019 liuGlobalReviewMonitoring2025a">(<a href="#ref-gogaReviewApplicationRemote2019" role="doc-biblioref">Goga et al., 2019</a>; <a href="#ref-liuGlobalReviewMonitoring2025a" role="doc-biblioref">Liu et al., 2025</a>)</span> and others), the I suggest the following methodology based on <span class="citation" data-cites="yinMappingAgriculturalLand2018 daraMappingTimingCropland2018 wuMonitoringCroplandAbandonment2023">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span> (mostly <span class="citation" data-cites="yinMappingAgriculturalLand2018">(<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span>).</p>
</section>
<section id="rationale-for-the-using-the-methodology" class="level2">
<h2 class="anchored" data-anchor-id="rationale-for-the-using-the-methodology">3.1. Rationale for the using the Methodology</h2>
<ul>
<li><p>Precise Temporal Detection: Unlike phenology-based methods that often provide only a broad window of change <span class="citation" data-cites="alcantaraMappingExtentAbandoned2013">(<a href="#ref-alcantaraMappingExtentAbandoned2013" role="doc-biblioref">Alcantara et al., 2013</a>)</span>, LandTrendr identifies the specific timing of abandonment and potential recultivation <span class="citation" data-cites="yinMappingAgriculturalLand2018 wuMonitoringCroplandAbandonment2023 daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span>.</p></li>
<li><p>Differentiation of Fallow vs.&nbsp;Abandonment: Phenology-based annual classifications often confuse temporary fallow years in a crop rotation cycle with permanent abandonment <span class="citation" data-cites="estelMappingFarmlandAbandonment2015 daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-estelMappingFarmlandAbandonment2015" role="doc-biblioref">Estel et al., 2015</a>)</span>. By analyzing the full temporal duration, the proposed method distinguishes these by applying a duration threshold (e.g., labeling abandonment only after 3–5 years of inactivity).</p></li>
<li><p>Noise Reduction via Trajectory Fitting: Instead of classifying each year independently, LandTrendr fits a geometrical model to the time series. This smoothes inter-annual noise related to climate or sensor variations, ensuring detected changes reflect real land-cover transitions rather than outliers <span class="citation" data-cites="yinMappingAgriculturalLand2018 daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span>.</p></li>
<li><p>Superior Accuracy: Previous studies, such as <span class="citation" data-cites="yinMappingAgriculturalLand2018">Yin et al. (<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">2018</a>)</span>, indicate that this trajectory-based method—especially when combined with Object-Based Image Analysis (OBIA)—can achieve overall accuracies as high as 97% ± 1%, compared to 82% for standard pixel-based approaches.</p></li>
<li><p>Training/Validation Sample Requirement: The sample data requirements for the suggested method (for generating agriculture land probability) focus on stable reference samples rather than year-specific (samples for each year separately) samples. This means it requires significantly less samples compared to agricultural land classification methods like <span class="citation" data-cites="estelMappingFarmlandAbandonment2015">(<a href="#ref-estelMappingFarmlandAbandonment2015" role="doc-biblioref">Estel et al., 2015</a>)</span>.</p></li>
</ul>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Analogy for Understanding:</strong> Phenology-based methods are like a security camera that only takes one photo each year; you can see if the field is green, but you can’t tell if the farmer just took a week off. Using LandTrendr + OBIA is like having a 30-year high-definition time-lapse video of the entire neighborhood; it allows you to ignore “camera flicker” (sensor noise) and see exactly when the farmer walked away and never came back.</p>
</div>
</div>
</div>
</section>
<section id="suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018" class="level2">
<h2 class="anchored" data-anchor-id="suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018">3.2. Suggested Methodology in Detail (based on <span class="citation" data-cites="yinMappingAgriculturalLand2018 wuMonitoringCroplandAbandonment2023 daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span>)</h2>
<p>This method is designed specifically to address the constraints related to topography of nepal, farming culture, cloud cover, time and other resources limitations, temporal coverage of freely available satellite data and so on.</p>
<p>The methodology uses an OBIA landTrendr approach applied to annual class probabilities.</p>
<ol type="1">
<li><p>Create agricultural land objects: The study will be carried out at object level to reduce “salt and pepper” noise common in pixel-based methods. The multi-resolution segmentation or similar algorithm will be applied to stacked Landsat images to create agricultural land objects <span class="citation" data-cites="yinMappingAgriculturalLand2018">(<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span>.</p>
<ul>
<li>Alternative 1: Use existing agricultural land from land cover datasets or osm or similar like <span class="citation" data-cites="wuMonitoringCroplandAbandonment2023">(<a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>)</span>.</li>
</ul></li>
<li><p>Data Acquisition and Preprocessing: GEE and python will be used for all the analysis if possible to keep the workflow easily repeatable and well documented.</p>
<ul>
<li><p>Datasets: Landsat (2000-2020/2024)</p></li>
<li><p>Preprocessing: Cloud Masking, Cloud Shadow Masking, Topographic Correction, Spectral and Textural Metrics</p></li>
<li><p>Cloud Gap filling: <span class="citation" data-cites="yusoffPhenologyClassificationAbandoned2017">Yusoff et al. (<a href="#ref-yusoffPhenologyClassificationAbandoned2017" role="doc-biblioref">2017</a>)</span> achieved 93% accuracy mapping abandoned paddy and rubber in tropical Malaysia using ALOS PALSAR (L-band Radar). They found that abandoned lands had distinct backscatter signatures compared to active fields.</p></li>
<li><p>Handelling Terraces: Spectal data alone might fail here. <span class="citation" data-cites="gunthertObjectbasedDetectionLUCC2011">Günthert et al. (<a href="#ref-gunthertObjectbasedDetectionLUCC2011" role="doc-biblioref">2011</a>)</span> used Edge Detection (Canny filter) algorithm combined with OBIA to map abandoned terraces. They found that active terraces have distinct linear textures (walls/furrows) that degrade upon abandonment. Using texture improved their accuracy to 91%. <span class="citation" data-cites="wuMonitoringCroplandAbandonment2023">(<a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>)</span> used Grey Level Co-occurrence Matrix (GLCM).</p></li>
<li><p>Training and Validation Samples: Method used by <span class="citation" data-cites="yinMappingAgriculturalLand2018 wuMonitoringCroplandAbandonment2023 wuMonitoringCroplandAbandonment2023">(<a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>, <a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">2023</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span> require training data for an RF classifier to generate annual cropland probability maps.</p>
<ul>
<li><p>For training, <span class="citation" data-cites="daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>)</span> used 1,800 sample pixels (900 for stable cropland and 900 for stable non-cropland). For validation, they used 1,290 independent reference samples. This included 50 pixels per stable class and 20–30 pixels per individual year of abandonment/recultivation to ensure the temporal accuracy was captured</p></li>
<li><p><span class="citation" data-cites="yinMappingAgriculturalLand2018">(<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span> used a larger set of approximately 3,000 Landsat pixel-size training samples, split evenly between active and non-active agriculture</p></li>
<li><p><span class="citation" data-cites="wuMonitoringCroplandAbandonment2023">(<a href="#ref-wuMonitoringCroplandAbandonment2023" role="doc-biblioref">Wu et al., 2023</a>)</span> validated their results using 262 abandoned points in 2018 and 296 points in 2020</p></li>
<li><p>The sources emphasize disproportionate stratified sampling. This ensures that rare events (like the specific year of abandonment) are adequately represented in the validation pool, as a purely random sample might mostly hit stable forest or stable farm plots <span class="citation" data-cites="yinMappingAgriculturalLand2018 daraMappingTimingCropland2018">(<a href="#ref-daraMappingTimingCropland2018" role="doc-biblioref">Dara et al., 2018</a>; <a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span>.</p></li>
<li><p>Source of Training Data: Researchers typically use a combination of historical Landsat imagery and high-resolution Google Earth archives to identify “stable” plots (areas that did not change during a specific window) to provide the baseline spectral signature for the classifier</p></li>
</ul></li>
</ul></li>
<li><p>Calculate Annual Provbability (probability of an object being agricultural land): Train RF classifier using samples of one reference year. I will apply this model to the whole time series. The output from this will be probability (0-100%) that an object is farmland in each year.</p></li>
<li><p>Apply landTrendr to Time Series Probabilities: Feed the annual probalities values into the landTrendr algorithm. This algorithm fits a trajectory curve to the probability history. It will identify “structural breaks”—specifically, the point where the probability of being farmland drops and stays low.</p></li>
<li><p>Classify Each Object into “AAL”, “Recultivated”, or “Fallow”: This will be based on threshold like <span class="citation" data-cites="yinMappingAgriculturalLand2018">(<a href="#ref-yinMappingAgriculturalLand2018" role="doc-biblioref">Yin et al., 2018</a>)</span> did.</p></li>
<li><p>Validation: Overall Accuracy, Kappa Coefficient, Producer’s Accuracy, User’s Accuracy</p></li>
</ol>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    %% --- Phase 1: Data Acquisition &amp; Preprocessing ---
    subgraph Phase1 ["Phase 1: Data Acquisition and Preprocessing (GEE and Python)"]
        A["Acquire Landsat Time Series&lt;br/&gt;2000-2024"] --&gt; B("Basic Preprocessing")
        B --&gt; B1["Cloud and Shadow Masking"]
        B --&gt; B2["Topographic Correction"]
        B --&gt; B3["Generate Spectral Metrics"]
        
        A -- Challenging Conditions --&gt; C("Specialized Preprocessing")
        C --&gt; C1["Cloud Gap Filling&lt;br/&gt;(Use Radar/ALOS PALSAR backscatter)"]
        C --&gt; C2["Handle Terraces/Texture&lt;br/&gt;(OBIA + Canny Filter or GLCM)"]
        
        B1 &amp; B2 &amp; B3 &amp; C1 &amp; C2 --&gt; D["Preprocessed Image Stack"]
    end

    %% --- Phase 2: Object Creation &amp; Sampling ---
    subgraph Phase2 ["Phase 2: OBIA and Sampling Strategy"]
        D --&gt; E{"Define Agricultural&lt;br/&gt;Land Objects"}
        E -- Primary Method --&gt; E1["OBIA: Multi-resolution Segmentation&lt;br/&gt;on Stacked Images"]
        E -- Alternative --&gt; E2["Use Existing Datasets&lt;br/&gt;(OSM, Land Cover Maps)"]
        E1 &amp; E2 --&gt; F["Final Agricultural Objects"]

        G["Define Training/Validation Samples&lt;br/&gt;(Historical Landsat/Google Earth)"] --&gt; H{"Sampling Design"}
        H -- "Crucial: Disproportionate Stratified Sampling" --&gt; H1["Ensure Representation of:&lt;br/&gt;Stable cropland, Stable non-cropland,&lt;br/&gt;Specific abandonment years"]
        F --&gt; I["Finalized Object&lt;br/&gt;Time Series Data"]
        H1 --&gt; J["Training and Validation Data Pool"]
    end

    %% --- Phase 3: Core Analysis (RF + LandTrendr) ---
    subgraph Phase3 ["Phase 3: Probability and Trajectory Analysis"]
        J -- Training Samples --&gt; K["Train Random Forest (RF) Classifier&lt;br/&gt;(Using reference year samples)"]
        I -- Object Data --&gt; L["Apply RF Model to&lt;br/&gt;Whole Time Series"]
        K --&gt; L
        L --&gt; M["Output: Annual Probability of&lt;br/&gt;being Farmland (0-100%) per Object"]
        
        M --&gt; N["Apply LandTrendr Algorithm&lt;br/&gt;to Probability Time Series"]
        N --&gt; O["Fit Trajectory Curve &amp;&lt;br/&gt;Identify 'Structural Breaks'"]
        O -- "Break = Probability drops and stays low" --&gt; O
    end

    %% --- Phase 4: Classification &amp; Validation ---
    subgraph Phase4 ["Phase 4: Classification and Validation"]
        O --&gt; P["Apply Duration Thresholds&lt;br/&gt;(to distinguish fallow vs permanent)"]
        P --&gt; Q{"Final Object Classification"}
        Q --&gt; R1["Active Agricultural Land - AAL"]
        Q --&gt; R2["Temporary Fallow"]
        Q --&gt; R3["Abandoned"]
        Q --&gt; R4["Recultivated"]

        R1 &amp; R2 &amp; R3 &amp; R4 --&gt; S["Validation against Reference Data"]
        J -- Validation Samples --&gt; S
        S --&gt; T["Final Metrics:&lt;br/&gt;Overall Accuracy, Kappa,&lt;br/&gt;Producer's Acc., User's Acc."]
    end

    style E fill: #fffda0,stroke:#e6b800,stroke-width:2px
    style H fill: #fffda0,stroke:#e6b800,stroke-width:2px
    style O fill: #d0f0c0,stroke:#339933,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-alcantaraMappingExtentAbandoned2013" class="csl-entry" role="listitem">
Alcantara, C., Kuemmerle, T., Baumann, M., Bragina, E. V., Griffiths, P., Hostert, P., Knorn, J., Müller, D., Prishchepov, A. V., Schierhorn, F., Sieber, A., &amp; Radeloff, V. C. (2013). Mapping the extent of abandoned farmland in Central and Eastern Europe using MODIS time series satellite data. <em>Environmental Research Letters</em>, <em>8</em>(3), 035035. <a href="https://doi.org/10.1088/1748-9326/8/3/035035">https://doi.org/10.1088/1748-9326/8/3/035035</a>
</div>
<div id="ref-daraMappingTimingCropland2018" class="csl-entry" role="listitem">
Dara, A., Baumann, M., Kuemmerle, T., Pflugmacher, D., Rabe, A., Griffiths, P., Hölzel, N., Kamp, J., Freitag, M., &amp; Hostert, P. (2018). Mapping the timing of cropland abandonment and recultivation in northern Kazakhstan using annual Landsat time series. <em>Remote Sensing of Environment</em>, <em>213</em>, 49–60. <a href="https://doi.org/10.1016/j.rse.2018.05.005">https://doi.org/10.1016/j.rse.2018.05.005</a>
</div>
<div id="ref-estelMappingFarmlandAbandonment2015" class="csl-entry" role="listitem">
Estel, S., Kuemmerle, T., Alcántara, C., Levers, C., Prishchepov, A., &amp; Hostert, P. (2015). Mapping farmland abandonment and recultivation across Europe using MODIS NDVI time series. <em>Remote Sensing of Environment</em>, <em>163</em>, 312–325. <a href="https://doi.org/10.1016/j.rse.2015.03.028">https://doi.org/10.1016/j.rse.2015.03.028</a>
</div>
<div id="ref-gogaReviewApplicationRemote2019" class="csl-entry" role="listitem">
Goga, T., Feranec, J., Bucha, T., Rusnák, M., Sačkov, I., Barka, I., Kopecká, M., Papčo, J., Oťaheľ, J., Szatmári, D., Pazúr, R., Sedliak, M., Pajtík, J., &amp; Vladovič, J. (2019). A Review of the Application of Remote Sensing Data for Abandoned Agricultural Land Identification with Focus on Central and Eastern Europe. <em>Remote Sensing</em>, <em>11</em>(23), 2759. <a href="https://doi.org/10.3390/rs11232759">https://doi.org/10.3390/rs11232759</a>
</div>
<div id="ref-goodinMappingLandCover2015" class="csl-entry" role="listitem">
Goodin, D. G., Anibas, K. L., &amp; Bezymennyi, M. (2015). Mapping land cover and land use from object-based classification: an example from a complex agricultural landscape. <em>International Journal of Remote Sensing</em>, <em>36</em>(18), 4702–4723. <a href="https://doi.org/10.1080/01431161.2015.1088674">https://doi.org/10.1080/01431161.2015.1088674</a>
</div>
<div id="ref-gunthertObjectbasedDetectionLUCC2011" class="csl-entry" role="listitem">
Günthert, S., Siegmund, A., Thunig, H., &amp; Michel, U. (2011). <em>Object-based detection of LUCC with special regard to agricultural abandonment on Tenerife (Canary Islands)</em> (U. Michel &amp; D. L. Civco, Eds.; p. 81811I). <a href="https://doi.org/10.1117/12.897583">https://doi.org/10.1117/12.897583</a>
</div>
<div id="ref-liuGlobalReviewMonitoring2025a" class="csl-entry" role="listitem">
Liu, T., Yu, L., Liu, X., Peng, D., Chen, X., Du, Z., Tu, Y., Wu, H., &amp; Zhao, Q. (2025). A Global Review of Monitoring Cropland Abandonment Using Remote Sensing: Temporal–Spatial Patterns, Causes, Ecological Effects, and Future Prospects. <em>Journal of Remote Sensing</em>, <em>5</em>, 0584. <a href="https://doi.org/10.34133/remotesensing.0584">https://doi.org/10.34133/remotesensing.0584</a>
</div>
<div id="ref-lowMappingAbandonedAgricultural2015" class="csl-entry" role="listitem">
Löw, F., Fliemann, E., Abdullaev, I., Conrad, C., &amp; Lamers, J. P. A. (2015). Mapping abandoned agricultural land in Kyzyl-Orda, Kazakhstan using satellite remote sensing. <em>Applied Geography</em>, <em>62</em>, 377–390. <a href="https://doi.org/10.1016/j.apgeog.2015.05.009">https://doi.org/10.1016/j.apgeog.2015.05.009</a>
</div>
<div id="ref-mullerComparingDeterminantsCropland2013" class="csl-entry" role="listitem">
Müller, D., Leitão, P. J., &amp; Sikor, T. (2013). Comparing the determinants of cropland abandonment in Albania and Romania using boosted regression trees. <em>Agricultural Systems</em>, <em>117</em>, 66–77. <a href="https://doi.org/10.1016/j.agsy.2012.12.010">https://doi.org/10.1016/j.agsy.2012.12.010</a>
</div>
<div id="ref-paudelHighResolutionRemoteSensing2025" class="csl-entry" role="listitem">
Paudel, B., Zhang, Y., Zhang, B., Gu, C., Liu, L., &amp; Khanal, N. R. (2025). High-Resolution Remote Sensing and People-to-Pixel Integration for Mapping Farmland Abandonment in Central Himalayan Villages. <em>Remote Sensing</em>, <em>17</em>(22), 3726. <a href="https://doi.org/10.3390/rs17223726">https://doi.org/10.3390/rs17223726</a>
</div>
<div id="ref-raiStatusFarmlandAbandonment2019" class="csl-entry" role="listitem">
Rai, R., Zhang, Y., Paudel, B., &amp; Khanal, N. (2019). Status of Farmland Abandonment and Its Determinants in the Transboundary Gandaki River Basin. <em>Sustainability</em>, <em>11</em>(19), 5267. <a href="https://doi.org/10.3390/su11195267">https://doi.org/10.3390/su11195267</a>
</div>
<div id="ref-shixinObjectorientedClassificationTechnique2013" class="csl-entry" role="listitem">
Shixin, W., Wenjun, L., Yi, Z., Futao, W., &amp; Qilong, X. (2013). <em>Object-oriented Classification Technique for Extracting Abandoned Farmlands by Using Remote Sensing Images:</em> 3rd International Conference on Multimedia Technology(ICMT-13), Guangzhou, China. <a href="https://doi.org/10.2991/icmt-13.2013.183">https://doi.org/10.2991/icmt-13.2013.183</a>
</div>
<div id="ref-stefanskiMappingMonitoringLand2014" class="csl-entry" role="listitem">
Stefanski, J., Chaskovskyy, O., &amp; Waske, B. (2014). Mapping and monitoring of land use changes in post-Soviet western Ukraine using remote sensing data. <em>Applied Geography</em>, <em>55</em>, 155–164. <a href="https://doi.org/10.1016/j.apgeog.2014.08.003">https://doi.org/10.1016/j.apgeog.2014.08.003</a>
</div>
<div id="ref-suziedelytevisockieneAnalysisIdentificationAbandoned2019" class="csl-entry" role="listitem">
Suziedelyte Visockiene, J., Tumeliene, E., &amp; Maliene, V. (2019). Analysis and identification of abandoned agricultural land using remote sensing methodology. <em>Land Use Policy</em>, <em>82</em>, 709–715. <a href="https://doi.org/10.1016/j.landusepol.2019.01.013">https://doi.org/10.1016/j.landusepol.2019.01.013</a>
</div>
<div id="ref-wuMonitoringCroplandAbandonment2023" class="csl-entry" role="listitem">
Wu, J., Jin, S., Zhu, G., &amp; Guo, J. (2023). Monitoring of Cropland Abandonment Based on Long Time Series Remote Sensing Data: A Case Study of Fujian Province, China. <em>Agronomy</em>, <em>13</em>(6), 1585. <a href="https://doi.org/10.3390/agronomy13061585">https://doi.org/10.3390/agronomy13061585</a>
</div>
<div id="ref-yinMappingAgriculturalLand2018" class="csl-entry" role="listitem">
Yin, H., Prishchepov, A. V., Kuemmerle, T., Bleyhl, B., Buchner, J., &amp; Radeloff, V. C. (2018). Mapping agricultural land abandonment from spatial and temporal segmentation of Landsat time series. <em>Remote Sensing of Environment</em>, <em>210</em>, 12–24. <a href="https://doi.org/10.1016/j.rse.2018.02.050">https://doi.org/10.1016/j.rse.2018.02.050</a>
</div>
<div id="ref-yusoffPhenologyClassificationAbandoned2017" class="csl-entry" role="listitem">
Yusoff, N. M., Muharam, F. M., Takeuchi, W., Darmawan, S., &amp; Abd Razak, M. H. (2017). Phenology and classification of abandoned agricultural land based on ALOS-1 and 2 PALSAR multi-temporal measurements. <em>International Journal of Digital Earth</em>, <em>10</em>(2), 155–174. <a href="https://doi.org/10.1080/17538947.2016.1216615">https://doi.org/10.1080/17538947.2016.1216615</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>