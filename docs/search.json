[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Agricultural Land Abandonment in Nepal",
    "section": "",
    "text": "Problem: Identify abandoned agricultural lands (AAL) in Nepal.\nSolution (Conceptual): Establish a quantifiable definition of AAL → Develop a method to identify AAL satisfying the definition."
  },
  {
    "objectID": "index.html#rationale-for-this-definition",
    "href": "index.html#rationale-for-this-definition",
    "title": "Agricultural Land Abandonment in Nepal",
    "section": "1.1. Rationale for this definition",
    "text": "1.1. Rationale for this definition\n\nQuantifiable supported by FAO (FAO, 2016)\nAvoids misclassifying temporary fallow land"
  },
  {
    "objectID": "index.html#review-of-existing-methods",
    "href": "index.html#review-of-existing-methods",
    "title": "Agricultural Land Abandonment in Nepal",
    "section": "2.1. Review of existing methods",
    "text": "2.1. Review of existing methods\nBased on (Liu et al., 2025), the methods can be divided into two major categories (Image classification & spectral features method and Time-dynamic &trajectory method) and various sub categories.\n\nImage Classification and Spectral Features Methods: This includes visual interpretation, supervised classification (SVM, Random Forest), decision trees, object-oriented classification (OBIA), and integrated methods (fusion of techniques).\nTime-Dynamic and Trajectory Methods: This includes dual time-point change detection, multi-time point land cover trajectories (like LandTrendr), and vegetation phenology dynamics.\n\n\n\n\n\n\ngraph TD\n    classDef default font-size:20px;\n\n    %% Main Node\n    Start[Methods for AAL Detection]\n\n    %% Main Categories\n    CA[Image classification and &lt;br&gt; spectral features method]\n    TT[Time-dynamic and &lt;br&gt; trajectory method]\n\n    %% CA Sub-points\n    CA_1[Visual &lt;br&gt; interpretation]\n    CA_2[Supervised &lt;br&gt; classification]\n    CA_3[Decision &lt;br&gt; trees]\n    CA_4[Object-oriented &lt;br&gt; classification]\n    CA_5[Integrated &lt;br&gt; methods]\n    \n    %% TT Sub-points\n    TT_1[Dual time point &lt;br&gt; land cover changes &lt;br&gt; Multi-time point &lt;br&gt; land cover trajectory]\n    TT_2[Vegetation phenology and &lt;br&gt; dynamic]\n\n    %% Connections\n    Start --&gt; TT\n    Start --&gt; CA\n\n    TT --&gt; TT_1\n    TT --&gt; TT_2\n\n    CA --&gt; CA_1\n    CA --&gt; CA_2\n    CA --&gt; CA_3\n    CA --&gt; CA_4\n    CA --&gt; CA_5\n\n    %% Styling\n    style Start fill:#2c3e50,stroke:#34495e,stroke-width:4px,color:#fff,font-weight:bold\n    style TT fill:#3498db,stroke:#2980b9,stroke-width:2px,color:#fff\n    style CA fill:#27ae60,stroke:#229954,stroke-width:2px,color:#fff\n    \n    style TT_1 fill:#ebf5fb,stroke:#3498db,stroke-dasharray: 5 5\n    style TT_2 fill:#ebf5fb,stroke:#3498db,stroke-dasharray: 5 5\n    \n    style CA_1 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5\n    style CA_2 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5\n    style CA_3 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5\n    style CA_4 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5\n    style CA_5 fill:#eafaf1,stroke:#27ae60,stroke-dasharray: 5 5\n\n\n\n\n\n\n\n\n\nLiu et al. (2025)\n\n\n\n2.1.1 Comparison of Methods\n\n\n\nLiu et al. (2025)\n\n\n\n\n\nTable 1: Comprehensive Comparison of Remote Sensing Methods for Abandoned Agricultural Land (AAL) Detection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy\nApproach\nStudy Area\nData Sources (Spatial & Temporal)\nDefinition of Abandonment\nMethodology / Algorithm\nAccuracy / Performance\n\n\n\n\n(Alcantara et al., 2013)\nMulti-temporal (MA)\nCentral & Eastern Europe\nMODIS NDVI (250m)Time-series: 2003–2009\nClass-based (Static): Land cultivated in the socialist period but covered by successional vegetation (grass/shrubs) during observation.\nSVM: Phenological metrics (start of season, amplitude) extracted via TIMESAT.\nModerate: ~49% area-adjusted overall accuracy.\n\n\n(Estel et al., 2015)\nMulti-temporal (MA)\nEurope\nMODIS NDVI (250m)Time-series: 2001–2012\nTrajectory-based: Land unmanaged/fallow for 2–5 consecutive years.\nRandom Forest (RF): Annual classification of “Active” vs. “Fallow” using normalized NDVI curves.\nHigh: ~90.1% average overall accuracy for active/fallow distinction.\n\n\n(Stefanski et al., 2014)\nOBIA / Multi-sensor\nWestern Ukraine\nLandsat (Optical) + ERS SAR (Radar)Years: 1986, 1993, 1999, 2006, 2010\nTrajectory-based: Land cover transition (Cropland → Grassland) without recultivation.\nOBIA + RF: Superpixel Contour segmentation to delineate fields. Fusion of Optical and Radar.\n83.4% Overall Accuracy. 87.2% for 2010 management regimes.\n\n\n(Löw et al., 2015)\nOBIA / Fusion\nKazakhstan\nLandsat + RapidEyeTime-series: 2009–2014\nTrajectory-based: Analyzed within historical field parcels. Abandonment = 5 years of shrub/bare cover.\nDecision Fusion: Trained RF and SVM separately on object-based features and fused results via majority voting.\n~97% Overall Accuracy. Fusing classifiers significantly improved accuracy over single algorithms.\n\n\n(Yin et al., 2018)\nOBIA / LandTrendr\nCaucasus (Russia/Georgia)\nLandsat time series (30m)1985–2015\nDynamic/Trajectory: Land inactive for at least 5 years (based on FAO definition).\nRF + LandTrendr: Multi-resolution segmentation into objects. RF for annual probability, then LandTrendr for temporal segmentation.\n97% ± 1% Overall Accuracy. Performed substantially better than pixel-level detection (82%).\n\n\n(Wu et al., 2023)\nOBIA / LandTrendr\nFujian Province, China\nLandsat + Sentinel-2 (10-30m)2010–2021\nNarrow Sense: Farmland not cultivated for 1 year or more.\nRF + LandTrendr: Used existing government farmland plot boundaries. RF for annual probability, then LandTrendr to identify significant drops.\nHigh: 87.02% (2018) and 87.50% (2020) validation accuracy.\n\n\n(Dara et al., 2018)\nMulti-temporal (MA)\nNorthern Kazakhstan\nLandsat time series (30m)1984–2016\nTrajectory-based: 3 consecutive years active followed by 3 consecutive years inactive.\nRF + LandTrendr: 3-year moving window for spectral metrics. RF for annual cropland probability, then LandTrendr for trajectory analysis.\n89% Overall Accuracy. UA of 93% for the abandonment class.\n\n\n(Günthert et al., 2011)\nTexture / Edge Detection\nTenerife (Canary Islands)\nRapidEye + Orthophotos2010\nSubtraction Method: (Total Ever-Utilized Area) minus (Current Active Agriculture).\nCanny Filter within OBIA: Detects “linear footprints” (terraces/walls) under vegetation to identify long-term fallow.\n93.0% Overall Accuracy. Highly effective for abandoned terraces.\n\n\n(Shixin et al., 2013)\nOBIA (Rule-based)\nChina\nSPOT-5 (2.5m/10m)Nov 2010\nLand Cover Class: Identification of abandoned land as a specific spectral/structural class.\nOBIA: Edge-based segmentation + rules involving spectral signatures, shape, and texture.\n78.94% accuracy for Abandoned Class. Outperformed pixel-based methods (~59%).\n\n\n(Goodin et al., 2015)\nOBIA / SVM\nPoland / Ukraine Border\nLandsat 8 OLI (Single date)Aug 2013\nLand Use Distinction: Differentiating “Pasture/Abandoned” from active “Arable” land.\nSVM within OBIA: Combined spectral features with object geometry (shape/size).\n75% Overall Accuracy for land use. Spatial features were essential for land use separation.\n\n\n(Suziedelyte Visockiene et al., 2019)\nSegmentation\nLithuania\nSentinel-2 (Optical)Sept 2017\nVerification: Land covered with woody plants identified by remote sensing and compared with national registry.\nMean-Shift Segmentation: Clustering and Kernel density (ColorMapping) to find homogenous scrub regions.\nVaried: ~94% (Winter), ~75% (Summer). Accuracy depends on seasonal vegetation state.\n\n\n\n\n\n\n\n\n\n\n\n\nNoteExpand for details\n\n\n\n\n\n\n2.1.1. Time-Dynamic and Trajectory Methods\nThese papers utilize advanced non-parametric classifiers like Random Forest (RF) and Support Vector Machine (SVM) and LandTrendR applied to time series data (mostly landsat and MODIS) to identify AAL.\n\n(Alcantara et al., 2013) used Support Vector Machine (SVM) on MODIS NDVI time series to map active and fallow agricultural lands across Europe.\n\n\n\n\n\n\n\nNoteDetails Alacantara et al. (2013)\n\n\n\n\n\n\nObjective: (1) What are the spatial patterns of currently abandoned farmland in Central and Eastern Europe?\n\n\nAre abandoned farmlands more strongly associated with institutional and socio-economic factors or with biophysical factors?\n\n\nDefinition: “Abandoned agriculture” was defined as land likely cultivated during the socialist period but covered by successional vegetation during the observation period. They classified pixels directly into four static classes: active agriculture, forest, abandoned agriculture, and other.\nDatasets:MODIS (both Aqua and Terra) NDVI time series (2003-2009) was classified into- active agriculture (cropland and pastures), forest, abandoned agriculture, and others (water, urban, rocks and wetland) using Support Vector Machine (SVM). TIMESAT software to extract specific phenological metrics. These included the start/end of the growing season, base/maximum NDVI, and the length of the growing cycle. They used 108 total bands (metrics plus monthly NDVI) as input\nClassification: They did not rely primarily on visual interpretation of the MODIS pixels themselves. Instead, they used an upscaling approach. They gathered training data from existing high-resolution (30m) Landsat land-cover maps produced in previous local studies. They selected MODIS pixels that contained at least 90% of a single class (e.g., abandoned agriculture) within the finer Landsat maps\n\n\n\n\n\n(Estel et al., 2015),used Random Forest classifier on MODIS NDVI time series (2001-2012) to map active and fallow agricultural lands across Europe.\n\n\n\n\n\n\n\nNoteDetails Estel et al. (2015)\n\n\n\n\n\n\nDefined fallow farmland as “land without management (i.e., not sown, cropped, or plowed in the case of cropland, or not mown or intensively grazed in the case of grassland)”.\nDatasets: MODIS NDVI (16 day composite Aqua & Terra), MODIS land surface temperature (to distinguish winter from growing season), MODIS land-water mask- MOD44W (to separate land area), GlobCORINE land cover (to define extent of potentially active or fallow agricultural land), training data-visual interpretation of MODIS NDVI profiles combined with high-res Google Earth images. They looked for specific phenological shapes: “bell-shaped” curves indicated fallow/natural vegetation, while irregular, narrow peaks indicated active management (plowing/harvest)\nClassification: They classified each pixel for each year as either “Active” or “Fallow” using RF classifier. Then, for each pixel, they calculated fallow frequency. Abandoned was then defined based on the trajectory (2-5 years of fallow years)\n\n\n\n\n\n(Müller et al., 2013) A pixel was classified as “abandoned” if it was covered by cropland in the first time step (e.g., 1990) but was not cropland (non-cropland) in the subsequent time step (e.g., 1995). Cannot use this because it does not consider temporary fallow agricultural land.\n\n\n\n\n\n\n\nNoteEstel et al. (2015) vs Alcantara et al. (2013)\n\n\n\n\n\n\n\n\nTable 2: Table 1: Major Differences Between the Two Methods\n\n\n\n\n\n\n\n\n\n\nFeature\nEstel et al. (2015)\nAlcantara et al. (2013)\n\n\n\n\nOutput Type\nAnnual Maps: Produces a map for every year (2001–2012) to track trajectories.\nStatic Map: Produces a single map representing the state of abandonment around 2005.\n\n\nInput Features\nNormalized Time Series: Used the shape of the NDVI curve directly after normalizing for climate differences.\nPhenological Metrics: Extracted specific statistics (e.g., start of season, amplitude) using TIMESAT software.\n\n\nAlgorithm\nRandom Forest (RF): Uses an ensemble of decision trees.\nSupport Vector Machines (SVM): Fits optimal hyperplanes to separate classes.\n\n\nTraining Data\nVisual Interpretation: Experts labeled points by looking at Google Earth and NDVI profiles.\nUpscaling/Fusion: Used existing high-resolution Landsat maps to train the coarse MODIS classifier.\n\n\nAbandonment Logic\nFrequency-based: A pixel is “abandoned” only if it is classified as “fallow” for several consecutive years.\nClass-based: The classifier is trained to recognize the specific spectral signature of “abandonment” as a distinct land cover class.\n\n\nAccuracy\nMore Accurate\nLess Accurate\n\n\n\n\n\n\n\n\n\n(Dara et al., 2018; Wu et al., 2023; Yin et al., 2018) share a core methodological framework for mapping AAL using LandTrendr algorithm on agricultural land probability (probabilities of pixel/object being cropland using Random Forest).\n\nCore Algorithm: All three studies utilize the LandTrendr (Landsat-based detection of Trends in Disturbance and Recovery) algorithm to analyze temporal trajectories. They all first employ a Random Forest classifier to generate annual probability maps (estimating the likelihood of a pixel/object being cropland) and then feed these probability time series into LandTrendr to detect structural breaks.\nClassification Probabilities: All of them use Random Forest to perform the initial classification of cropland probabilities based on spectral metrics.\nTrajectory Analysis: They distinguish stable cropland from abandoned and recultivated cropland based on the trajectory of the probability values over time.\nMajor difference: (Dara et al., 2018) addressed data scarcity by calculating spectral metrics using a 3-year moving window rather than single-year images. (Yin et al., 2018) included imagery from +- 1 year around the target year to calculate spectral-temporal metrics and reduce classification error due to data gaps. (Wu et al., 2023) combined Landsat with Sentinel-2 data and used monthly synthetic cloud-free images set to construct their time series, rather than multi-year moving window.\n\n\n\n2.1.2. Image Classification and Spectral Features Methods\nThese papers deviate away from the pixel-based approach towards object-based image analysis (OBIA), multi-sensor data fusion, and long-term tragectory analysis.\n\n(Stefanski et al., 2014) (Optical-Radar Fusion & Trajectory Analysis): This study focuses on the post-Soviet Western Ukraine and utilizes a method that integrates different sensor types to overcome data gaps and spectral confusion.\n\n\n\n\n\n\n\nNoteDetails Stefanski et al. (2014)\n\n\n\n\n\n\nData: They combined optical data (Landsat) with Radar data (ERS SAR) for the years 1986, 1993, 1999, 2006, and 2010.\nMethod: They applied OBIA approach using “Superpixel Contour” segmentation to delineate fields. They then classified these objects using Random Forest classifier.\nAbandonment: Abandonment was identified through land cover trajectory analysis. They tracked the trajectory of each object across the five time steps. E.g., Cropland → Grassland (without recultivation) = Permanent Abandonment\n\n\n\n\n\n(Löw et al., 2015) (Decision Fusion & Historical Vector Masking): Focused on Kazakhstan, this paper introduces a “Decision Fusion” technique to improve accuracy in complex irrigated landscape.\n\n\n\n\n\n\n\nNoteDetails Low et al. (2015)\n\n\n\n\n\n\nData: Time series of Landsat and RapidEye imagery (2009-2014)\nMethod: They used two different machine learning algorithms, RF and SVM to classify the data. they then fused the results of these two classifiers to achieve higher accuracy (up tp 97%) than either could achieve alone.\nAbandonment: They digitized all formerly used field parcels (from Soviet era) using hi-res imagery to create a mask. They then analyzed the land cover trahectories within the specific polygons to identify abandonment. E.g., 5 consecutive years of shrub cover/bare.\n\n\n\n\n\n(Günthert et al., 2011) (Texture-Based “Subtraction” Method): Günthert et al. developed a unique “subtraction” method that relies on identifying physical land structures rather than just vegetation health. Their approach was driven by the specific landscape of Tenerife, where agriculture relies on terraces that remain visible even long after the land has been abandoned and covered by natural vegetation\n\n\n\n\n\n\n\nNoteDetails Günthert et al. (2011)\n\n\n\n\n\n\nData: RapidEye satellite imagery & hi-res orthophotos\nMethod: OBIA approach on rapidEye to id current active crops. Applied Canny edge detector on very hi-res orthophotos to find the “footprint” of all agriculture past and present. This is termed as “Total Ever-utilized” land. Instead of loooking for green vegetation, they looked for linear structures like terrace walls, plough dfurrows, and field boundaries. They used a Canny edge detector filter to highlight these lines, followed by a density analysis to identify areas with a high concentration of man-made lines. This allowed them to detect old agricultural land even if it was covered in dense shrubs or forest (advanced secondary succession).\nAbandonment:They calculated abandonment by subtracting the Current Active Agriculture (Step 1) from the Total Ever-Utilized Area (Step 2). Any area that had agricultural terraces (Step 2) but was not currently being farmed (Step 1) was classified as abandoned/non-active\n\n\n\n\n\n(Shixin et al., 2013) This paper focuses on proving the superiority of object-based methods over pixel-based methods using high-resolution data in China.\n\n\n\n\n\n\n\nNoteDetails Shixin et al. (2013)\n\n\n\n\n\n\nData: SPOT-5 high-resolution imagery (2.5m panchromatic and 10m multispectral)\nMethod: They performed Edge-based segmentation in ENVI software to create image objects. They then classified these objects using a rule-based system involving spectral signatures, shape, texture, and spatial location.\nAbandonment: They compared this directly with a standard pixel-based Maximum Likelihood classification. The object-oriented method achieved an accuracy of 78.94% for abandoned farmland, whereas the pixel-based method achieved only 59.00%, primarily because abandoned land is spectrally complex (mixed weeds, soil, water) and confuses pixel-based classifiers\n\n\n\n\n\n(Goodin et al., 2015) This study explicitly tests which components of an object (spectral vs. spatial) are necessary to identify land use (abandonment) versus land cover.\n\n\n\n\n\n\n\nNoteDetails Goodin et al. (2015)\n\n\n\n\n\n\nData: Single-date Landsat 8 OLI imagery (pan-sharpened)\nMethod: They used Support Vector Machines (SVM) within an Object-Based Image Analysis (OBIA) framework. They ran three variations: using only spectral features, using only spatial/geometric features, and using combined features\nAbandonment: They found that for land use (which includes distinguishing “Pasture/Abandoned” from active “Arable”), using combined spectral and spatial features yielded the highest accuracy. This confirms that the shape and size of agricultural plots (geometry) are critical cues for identifying abandonment in fragmented landscapes\n\n\n\n\n\n(Suziedelyte Visockiene et al., 2019) (Segmentation & Spatial Data Comparison) This paper analyzes abandoned land in Lithuania using open-source satellite data and compares it to national registry data.\n\n\n\n\n\n\n\nNoteDetails Suziedelyte-Visockiene et al. (2019)\n\n\n\n\n\n\nData: Sentinel-2 optical data.\nMethod: They used the Mean-Shift segmentation algorithm to group pixels into regions of homogeneous color and density. They used a “ColorMapping” application based on Kernel density estimation.\nAbandonment: They compared the results of this segmentation with the national “collection of spatial data on abandoned agricultural land” (vector data provided by the National Land Service). This served as a validation of using remote sensing to update official national statistics"
  },
  {
    "objectID": "index.html#multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm",
    "href": "index.html#multitemporal-object-oriented-image-analysis-based-on-phenology-using-landtrendr-algorithm",
    "title": "Agricultural Land Abandonment in Nepal",
    "section": "Multitemporal Object-oriented Image Analysis Based on Phenology using landTrendr algorithm",
    "text": "Multitemporal Object-oriented Image Analysis Based on Phenology using landTrendr algorithm\nBased on the review of literature ((Goga et al., 2019; Liu et al., 2025) and others), the I suggest the following methodology based on (Dara et al., 2018; Wu et al., 2023; Yin et al., 2018) (mostly (Yin et al., 2018))."
  },
  {
    "objectID": "index.html#rationale-for-the-using-the-methodology",
    "href": "index.html#rationale-for-the-using-the-methodology",
    "title": "Agricultural Land Abandonment in Nepal",
    "section": "3.1. Rationale for the using the Methodology",
    "text": "3.1. Rationale for the using the Methodology\n\nPrecise Temporal Detection: Unlike phenology-based methods that often provide only a broad window of change (Alcantara et al., 2013), LandTrendr identifies the specific timing of abandonment and potential recultivation (Dara et al., 2018; Wu et al., 2023; Yin et al., 2018).\nDifferentiation of Fallow vs. Abandonment: Phenology-based annual classifications often confuse temporary fallow years in a crop rotation cycle with permanent abandonment (Dara et al., 2018; Estel et al., 2015). By analyzing the full temporal duration, the proposed method distinguishes these by applying a duration threshold (e.g., labeling abandonment only after 3–5 years of inactivity).\nNoise Reduction via Trajectory Fitting: Instead of classifying each year independently, LandTrendr fits a geometrical model to the time series. This smoothes inter-annual noise related to climate or sensor variations, ensuring detected changes reflect real land-cover transitions rather than outliers (Dara et al., 2018; Yin et al., 2018).\nSuperior Accuracy: Previous studies, such as Yin et al. (2018), indicate that this trajectory-based method—especially when combined with Object-Based Image Analysis (OBIA)—can achieve overall accuracies as high as 97% ± 1%, compared to 82% for standard pixel-based approaches.\nTraining/Validation Sample Requirement: The sample data requirements for the suggested method (for generating agriculture land probability) focus on stable reference samples rather than year-specific (samples for each year separately) samples. This means it requires significantly less samples compared to agricultural land classification methods like (Estel et al., 2015).\n\n\n\n\n\n\n\nAnalogy for Understanding: Phenology-based methods are like a security camera that only takes one photo each year; you can see if the field is green, but you can’t tell if the farmer just took a week off. Using LandTrendr + OBIA is like having a 30-year high-definition time-lapse video of the entire neighborhood; it allows you to ignore “camera flicker” (sensor noise) and see exactly when the farmer walked away and never came back."
  },
  {
    "objectID": "index.html#suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018",
    "href": "index.html#suggested-methodology-in-detail-based-on-yinmappingagriculturalland2018-wumonitoringcroplandabandonment2023-daramappingtimingcropland2018",
    "title": "Agricultural Land Abandonment in Nepal",
    "section": "3.2. Suggested Methodology in Detail (based on (Dara et al., 2018; Wu et al., 2023; Yin et al., 2018))",
    "text": "3.2. Suggested Methodology in Detail (based on (Dara et al., 2018; Wu et al., 2023; Yin et al., 2018))\nThis method is designed specifically to address the constraints related to topography of nepal, farming culture, cloud cover, time and other resources limitations, temporal coverage of freely available satellite data and so on.\nThe methodology uses an OBIA landTrendr approach applied to annual class probabilities.\n\nCreate agricultural land objects: The study will be carried out at object level to reduce “salt and pepper” noise common in pixel-based methods. The multi-resolution segmentation or similar algorithm will be applied to stacked Landsat images to create agricultural land objects (Yin et al., 2018).\n\nAlternative 1: Use existing agricultural land from land cover datasets or osm or similar like (Wu et al., 2023).\n\nData Acquisition and Preprocessing: GEE and python will be used for all the analysis if possible to keep the workflow easily repeatable and well documented.\n\nDatasets: Landsat (2000-2020/2024)\nPreprocessing: Cloud Masking, Cloud Shadow Masking, Topographic Correction, Spectral and Textural Metrics\nCloud Gap filling: Yusoff et al. (2017) achieved 93% accuracy mapping abandoned paddy and rubber in tropical Malaysia using ALOS PALSAR (L-band Radar). They found that abandoned lands had distinct backscatter signatures compared to active fields.\nHandelling Terraces: Spectal data alone might fail here. Günthert et al. (2011) used Edge Detection (Canny filter) algorithm combined with OBIA to map abandoned terraces. They found that active terraces have distinct linear textures (walls/furrows) that degrade upon abandonment. Using texture improved their accuracy to 91%. (Wu et al., 2023) used Grey Level Co-occurrence Matrix (GLCM).\nTraining and Validation Samples: Method used by (Wu et al., 2023, 2023; Yin et al., 2018) require training data for an RF classifier to generate annual cropland probability maps.\n\nFor training, (Dara et al., 2018) used 1,800 sample pixels (900 for stable cropland and 900 for stable non-cropland). For validation, they used 1,290 independent reference samples. This included 50 pixels per stable class and 20–30 pixels per individual year of abandonment/recultivation to ensure the temporal accuracy was captured\n(Yin et al., 2018) used a larger set of approximately 3,000 Landsat pixel-size training samples, split evenly between active and non-active agriculture\n(Wu et al., 2023) validated their results using 262 abandoned points in 2018 and 296 points in 2020\nThe sources emphasize disproportionate stratified sampling. This ensures that rare events (like the specific year of abandonment) are adequately represented in the validation pool, as a purely random sample might mostly hit stable forest or stable farm plots (Dara et al., 2018; Yin et al., 2018).\nSource of Training Data: Researchers typically use a combination of historical Landsat imagery and high-resolution Google Earth archives to identify “stable” plots (areas that did not change during a specific window) to provide the baseline spectral signature for the classifier\n\n\nCalculate Annual Provbability (probability of an object being agricultural land): Train RF classifier using samples of one reference year. I will apply this model to the whole time series. The output from this will be probability (0-100%) that an object is farmland in each year.\nApply landTrendr to Time Series Probabilities: Feed the annual probalities values into the landTrendr algorithm. This algorithm fits a trajectory curve to the probability history. It will identify “structural breaks”—specifically, the point where the probability of being farmland drops and stays low.\nClassify Each Object into “AAL”, “Recultivated”, or “Fallow”: This will be based on threshold like (Yin et al., 2018) did.\nValidation: Overall Accuracy, Kappa Coefficient, Producer’s Accuracy, User’s Accuracy\n\n\n\n\n\n\ngraph TD\n    %% --- Phase 1: Data Acquisition & Preprocessing ---\n    subgraph Phase1 [\"Phase 1: Data Acquisition and Preprocessing (GEE and Python)\"]\n        A[\"Acquire Landsat Time Series&lt;br/&gt;2000-2024\"] --&gt; B(\"Basic Preprocessing\")\n        B --&gt; B1[\"Cloud and Shadow Masking\"]\n        B --&gt; B2[\"Topographic Correction\"]\n        B --&gt; B3[\"Generate Spectral Metrics\"]\n        \n        A -- Challenging Conditions --&gt; C(\"Specialized Preprocessing\")\n        C --&gt; C1[\"Cloud Gap Filling&lt;br/&gt;(Use Radar/ALOS PALSAR backscatter)\"]\n        C --&gt; C2[\"Handle Terraces/Texture&lt;br/&gt;(OBIA + Canny Filter or GLCM)\"]\n        \n        B1 & B2 & B3 & C1 & C2 --&gt; D[\"Preprocessed Image Stack\"]\n    end\n\n    %% --- Phase 2: Object Creation & Sampling ---\n    subgraph Phase2 [\"Phase 2: OBIA and Sampling Strategy\"]\n        D --&gt; E{\"Define Agricultural&lt;br/&gt;Land Objects\"}\n        E -- Primary Method --&gt; E1[\"OBIA: Multi-resolution Segmentation&lt;br/&gt;on Stacked Images\"]\n        E -- Alternative --&gt; E2[\"Use Existing Datasets&lt;br/&gt;(OSM, Land Cover Maps)\"]\n        E1 & E2 --&gt; F[\"Final Agricultural Objects\"]\n\n        G[\"Define Training/Validation Samples&lt;br/&gt;(Historical Landsat/Google Earth)\"] --&gt; H{\"Sampling Design\"}\n        H -- \"Crucial: Disproportionate Stratified Sampling\" --&gt; H1[\"Ensure Representation of:&lt;br/&gt;Stable cropland, Stable non-cropland,&lt;br/&gt;Specific abandonment years\"]\n        F --&gt; I[\"Finalized Object&lt;br/&gt;Time Series Data\"]\n        H1 --&gt; J[\"Training and Validation Data Pool\"]\n    end\n\n    %% --- Phase 3: Core Analysis (RF + LandTrendr) ---\n    subgraph Phase3 [\"Phase 3: Probability and Trajectory Analysis\"]\n        J -- Training Samples --&gt; K[\"Train Random Forest (RF) Classifier&lt;br/&gt;(Using reference year samples)\"]\n        I -- Object Data --&gt; L[\"Apply RF Model to&lt;br/&gt;Whole Time Series\"]\n        K --&gt; L\n        L --&gt; M[\"Output: Annual Probability of&lt;br/&gt;being Farmland (0-100%) per Object\"]\n        \n        M --&gt; N[\"Apply LandTrendr Algorithm&lt;br/&gt;to Probability Time Series\"]\n        N --&gt; O[\"Fit Trajectory Curve &&lt;br/&gt;Identify 'Structural Breaks'\"]\n        O -- \"Break = Probability drops and stays low\" --&gt; O\n    end\n\n    %% --- Phase 4: Classification & Validation ---\n    subgraph Phase4 [\"Phase 4: Classification and Validation\"]\n        O --&gt; P[\"Apply Duration Thresholds&lt;br/&gt;(to distinguish fallow vs permanent)\"]\n        P --&gt; Q{\"Final Object Classification\"}\n        Q --&gt; R1[\"Active Agricultural Land - AAL\"]\n        Q --&gt; R2[\"Temporary Fallow\"]\n        Q --&gt; R3[\"Abandoned\"]\n        Q --&gt; R4[\"Recultivated\"]\n\n        R1 & R2 & R3 & R4 --&gt; S[\"Validation against Reference Data\"]\n        J -- Validation Samples --&gt; S\n        S --&gt; T[\"Final Metrics:&lt;br/&gt;Overall Accuracy, Kappa,&lt;br/&gt;Producer's Acc., User's Acc.\"]\n    end\n\n    style E fill: #fffda0,stroke:#e6b800,stroke-width:2px\n    style H fill: #fffda0,stroke:#e6b800,stroke-width:2px\n    style O fill: #d0f0c0,stroke:#339933,stroke-width:2px"
  }
]